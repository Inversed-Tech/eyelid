name: Monitor Benchmark Changes

on:
  workflow_dispatch:

  push:
    branches:
      - main

  # Security: this workflow runs on all PRs, but only writes results for local branches
  pull_request:

concurrency:
  group: '${{ github.workflow }} @ ${{ github.event.pull_request.head.label || github.head_ref || github.ref }}'
  cancel-in-progress: true

# The actions variables and shell env namespaces are different, so we need to import every relevant variable here:
# <https://github.com/Inversed-Tech/eyelid/settings/variables/actions>
env:
  # Logging
  CARGO_TERM_COLOR: ${{ vars.CARGO_TERM_COLOR }}
  # For performance reasons, benchmarks have their own log level, which should typically be `off` or `0`.
  RUST_LOG: ${{ vars.RUST_LOG_BENCHMARKS }}
  # These backtrace variables are used by the `backtrace` crate to control the backtrace verbosity in binaries and libraries.
  # We always want them set to the same value in CI. 
  RUST_BACKTRACE: ${{ vars.RUST_BACKTRACE_BENCHMARKS }}
  RUST_LIB_BACKTRACE: ${{ vars.RUST_BACKTRACE_BENCHMARKS }}

permissions:
  # Leaving performance comments on commits.
  # And later, writing results to the gh-pages branch (#53).
  contents: write
  # Performance comments on PRs
  pull-requests: write

jobs:
  bench-monitor:
    name: Performance regression check
    runs-on: ubuntu-latest
    steps:
     - uses: actions/checkout@v4
     - uses: r7kamura/rust-problem-matchers@v1

     - name: Build Benchmarks
       run: |
         export RUSTFLAGS="-D warnings"
         cargo bench --no-run --features benchmark --all-targets

     # Only run important benchmarks, and store their output to a file
     # We just need to run high-level functions here, because their benchmark will capture any significant changes in low-level operations
     - name: Run Important Benchmarks
       run: |
         export RUSTFLAGS="-D warnings"
         echo "Warning: benchmark timings are unreliable in CI due to virtualization"
         cargo bench --features benchmark -- 'match|multiplication|inv' --output-format bencher | tee output.txt
         echo "Warning: benchmark timings are unreliable in CI due to virtualization"

     # Download previous benchmark result from the most recent `main` branch cache (if any exists).
     # <https://github.com/actions/cache/blob/main/tips-and-workarounds.md#update-a-cache>
     - name: Download previous benchmark data
       uses: actions/cache@v4
       with:
         path: ./cache
         # Use a unique key to always save a new cache.
         # The commit hash isn't enough, because we also want to re-run the benchmark if the environment changes.
         key: ${{ runner.os }}-benchmark-${{ github.sha }}-${{ github.run_id }}
         # Download the most recent cache for this OS using a prefix.
         # <https://github.com/actions/cache/blob/main/caching-strategies.md#using-restore-keys-to-download-the-closest-matching-cache>
         restore-keys: |
           ${{ runner.os }}-benchmark

     # Debugging
     - name: Show cache before update
       run: |
         cat output.txt
         cat ./cache/benchmark-data.json || echo "No cached benchmark-data.json"
         cp ./cache/benchmark-data.json /tmp/old-benchmark-data.json || echo "No cached benchmark-data.json"
  
     # Run `github-action-benchmark` action
     - name: Store benchmark result
       uses: benchmark-action/github-action-benchmark@v1
       with:
         # What benchmark tool the output.txt came from
         tool: 'cargo'
         # Where the output from the benchmark tool is stored
         output-file-path: output.txt
  
         # Where the previous data file is stored
         external-data-json-path: ./cache/benchmark-data.json

         # Post an alert comment if performance gets this much worse. (Rather than an info comment.)
         # Because GitHub uses virtualization and shared machines, this is higher than we might want.
         # These values must be above 100%, because that means "no performance change".
         alert-threshold: "130%"
         # Workflow will fail if performance gets this much worse.
         fail-threshold: "150%"
         # Workflow will always comment on the PR, even if there is no performance change
         comment-always: true
         # Access token to post comments on PRs
         github-token: ${{ secrets.GITHUB_TOKEN }}
         
         # Upload the updated cache file for the next job by actions/cache,
         # if it's for the main branch. But don't record PR or manual workflow results. 
         save-data-file: ${{ github.event_name != 'pull_request' }}
  
     # Debugging
     - name: Show cache after update
       run: |
         cat output.txt
         cat ./cache/benchmark-data.json || echo "No cached benchmark-data.json"
         diff -u /tmp/old-benchmark-data.json ./cache/benchmark-data.json || echo "Differences were found, or no cached benchmark-data.json"
